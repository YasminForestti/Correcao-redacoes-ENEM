{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Import  data and librarys "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/all_features_data.csv\")\n",
    "data = data.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.254151</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.082645</td>\n",
       "      <td>0.127660</td>\n",
       "      <td>0.151715</td>\n",
       "      <td>0.224422</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.446999</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.203857</td>\n",
       "      <td>0.245863</td>\n",
       "      <td>0.226913</td>\n",
       "      <td>0.382838</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.475096</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.192837</td>\n",
       "      <td>0.203310</td>\n",
       "      <td>0.284960</td>\n",
       "      <td>0.336634</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.210728</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.168044</td>\n",
       "      <td>0.073286</td>\n",
       "      <td>0.096306</td>\n",
       "      <td>0.231023</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.234994</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.112948</td>\n",
       "      <td>0.073286</td>\n",
       "      <td>0.147757</td>\n",
       "      <td>0.224422</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2159</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.321839</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.173554</td>\n",
       "      <td>0.198582</td>\n",
       "      <td>0.138522</td>\n",
       "      <td>0.260726</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2160</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.401022</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.148760</td>\n",
       "      <td>0.205674</td>\n",
       "      <td>0.228232</td>\n",
       "      <td>0.306931</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2161</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.306513</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.198347</td>\n",
       "      <td>0.248227</td>\n",
       "      <td>0.083113</td>\n",
       "      <td>0.336634</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2162</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.384419</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.154270</td>\n",
       "      <td>0.193853</td>\n",
       "      <td>0.215040</td>\n",
       "      <td>0.412541</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2163</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.395913</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.107438</td>\n",
       "      <td>0.226950</td>\n",
       "      <td>0.230871</td>\n",
       "      <td>0.270627</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2164 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6     7  \\\n",
       "0     0.50  0.254151  0.142857  0.082645  0.127660  0.151715  0.224422  0.00   \n",
       "1     0.50  0.446999  0.142857  0.203857  0.245863  0.226913  0.382838  0.25   \n",
       "2     0.25  0.475096  0.095238  0.192837  0.203310  0.284960  0.336634  0.50   \n",
       "3     0.50  0.210728  0.095238  0.168044  0.073286  0.096306  0.231023  0.50   \n",
       "4     0.50  0.234994  0.142857  0.112948  0.073286  0.147757  0.224422  0.00   \n",
       "...    ...       ...       ...       ...       ...       ...       ...   ...   \n",
       "2159  0.75  0.321839  0.142857  0.173554  0.198582  0.138522  0.260726  0.00   \n",
       "2160  0.75  0.401022  0.190476  0.148760  0.205674  0.228232  0.306931  0.00   \n",
       "2161  0.50  0.306513  0.095238  0.198347  0.248227  0.083113  0.336634  0.00   \n",
       "2162  0.75  0.384419  0.142857  0.154270  0.193853  0.215040  0.412541  0.00   \n",
       "2163  0.50  0.395913  0.142857  0.107438  0.226950  0.230871  0.270627  0.00   \n",
       "\n",
       "             8    9  ...   16    17        18        19        20        21  \\\n",
       "0     0.000000  0.0  ...  0.0  0.00  0.000000  0.000000  0.000000  0.000000   \n",
       "1     0.000000  0.2  ...  0.0  0.00  0.000000  0.333333  0.000000  0.000000   \n",
       "2     0.066667  0.0  ...  0.0  0.00  0.166667  0.333333  0.333333  0.142857   \n",
       "3     0.200000  0.0  ...  0.0  0.00  0.166667  0.166667  0.000000  0.000000   \n",
       "4     0.133333  0.0  ...  0.0  0.00  0.166667  0.333333  0.000000  0.000000   \n",
       "...        ...  ...  ...  ...   ...       ...       ...       ...       ...   \n",
       "2159  0.066667  0.0  ...  0.0  0.25  0.000000  0.166667  0.000000  0.000000   \n",
       "2160  0.000000  0.0  ...  0.2  0.00  0.000000  0.166667  0.000000  0.000000   \n",
       "2161  0.000000  0.0  ...  0.0  0.00  0.000000  0.333333  0.333333  0.000000   \n",
       "2162  0.000000  0.0  ...  0.0  0.00  0.000000  0.000000  0.000000  0.000000   \n",
       "2163  0.000000  0.0  ...  0.0  0.00  0.000000  0.333333  0.666667  0.142857   \n",
       "\n",
       "       22   23        24        25  \n",
       "0     0.2  0.0  0.035714  0.111111  \n",
       "1     0.3  0.0  0.035714  0.444444  \n",
       "2     0.1  0.0  0.000000  0.333333  \n",
       "3     0.1  0.0  0.000000  0.111111  \n",
       "4     0.1  0.0  0.000000  0.444444  \n",
       "...   ...  ...       ...       ...  \n",
       "2159  0.3  0.0  0.035714  0.222222  \n",
       "2160  0.0  0.0  0.142857  0.111111  \n",
       "2161  0.1  0.0  0.107143  0.444444  \n",
       "2162  0.2  0.0  0.142857  0.444444  \n",
       "2163  0.0  0.0  0.000000  0.333333  \n",
       "\n",
       "[2164 rows x 26 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.iloc[:,0]\n",
    "X = data.iloc[:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "yfit = pd.get_dummies(y,dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(X,yfit, test_size=0.2, random_state=42)\n",
    "train_X, val_X ,train_y, val_y = train_test_split(train_X,train_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(15, input_dim=24, activation='tanh'))\n",
    "model.add(Dense(10, activation='tanh'))\n",
    "model.add(Dense(13, activation='tanh'))\n",
    "model.add(Dense(8, activation='tanh'))\n",
    "model.add(Dense(5, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "70/70 [==============================] - 2s 5ms/step - loss: 1.4779 - accuracy: 0.3642 - val_loss: 1.3763 - val_accuracy: 0.4207\n",
      "Epoch 2/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.3879 - accuracy: 0.4039 - val_loss: 1.3638 - val_accuracy: 0.4207\n",
      "Epoch 3/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.3798 - accuracy: 0.4046 - val_loss: 1.3638 - val_accuracy: 0.4179\n",
      "Epoch 4/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.3729 - accuracy: 0.4061 - val_loss: 1.3504 - val_accuracy: 0.4207\n",
      "Epoch 5/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.3634 - accuracy: 0.4068 - val_loss: 1.3428 - val_accuracy: 0.4294\n",
      "Epoch 6/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.3503 - accuracy: 0.4169 - val_loss: 1.3259 - val_accuracy: 0.4380\n",
      "Epoch 7/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.3293 - accuracy: 0.4256 - val_loss: 1.3035 - val_accuracy: 0.4352\n",
      "Epoch 8/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.3100 - accuracy: 0.4285 - val_loss: 1.2883 - val_accuracy: 0.4207\n",
      "Epoch 9/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.2949 - accuracy: 0.4465 - val_loss: 1.2718 - val_accuracy: 0.4496\n",
      "Epoch 10/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.2783 - accuracy: 0.4436 - val_loss: 1.2609 - val_accuracy: 0.4524\n",
      "Epoch 11/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.2694 - accuracy: 0.4501 - val_loss: 1.2515 - val_accuracy: 0.4784\n",
      "Epoch 12/1000\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1.2616 - accuracy: 0.4530 - val_loss: 1.2480 - val_accuracy: 0.4553\n",
      "Epoch 13/1000\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2568 - accuracy: 0.4509 - val_loss: 1.2541 - val_accuracy: 0.4294\n",
      "Epoch 14/1000\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1.2515 - accuracy: 0.4451 - val_loss: 1.2384 - val_accuracy: 0.4582\n",
      "Epoch 15/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.2482 - accuracy: 0.4509 - val_loss: 1.2336 - val_accuracy: 0.4553\n",
      "Epoch 16/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.2429 - accuracy: 0.4552 - val_loss: 1.2327 - val_accuracy: 0.4524\n",
      "Epoch 17/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.2428 - accuracy: 0.4610 - val_loss: 1.2306 - val_accuracy: 0.4524\n",
      "Epoch 18/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.2385 - accuracy: 0.4595 - val_loss: 1.2486 - val_accuracy: 0.4294\n",
      "Epoch 19/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.2405 - accuracy: 0.4523 - val_loss: 1.2399 - val_accuracy: 0.4467\n",
      "Epoch 20/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.2347 - accuracy: 0.4552 - val_loss: 1.2454 - val_accuracy: 0.4352\n",
      "Epoch 21/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.2337 - accuracy: 0.4552 - val_loss: 1.2528 - val_accuracy: 0.4294\n",
      "Epoch 22/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.2354 - accuracy: 0.4610 - val_loss: 1.2521 - val_accuracy: 0.4265\n",
      "Epoch 23/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.2296 - accuracy: 0.4646 - val_loss: 1.2438 - val_accuracy: 0.4265\n",
      "Epoch 24/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.2293 - accuracy: 0.4581 - val_loss: 1.2349 - val_accuracy: 0.4467\n",
      "Epoch 25/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.2293 - accuracy: 0.4538 - val_loss: 1.2353 - val_accuracy: 0.4323\n",
      "Epoch 26/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.2271 - accuracy: 0.4624 - val_loss: 1.2350 - val_accuracy: 0.4409\n",
      "Epoch 27/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.2260 - accuracy: 0.4632 - val_loss: 1.2401 - val_accuracy: 0.4294\n",
      "Epoch 28/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.2279 - accuracy: 0.4660 - val_loss: 1.2372 - val_accuracy: 0.4323\n",
      "Epoch 29/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.2264 - accuracy: 0.4559 - val_loss: 1.2530 - val_accuracy: 0.4236\n",
      "Epoch 30/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.2250 - accuracy: 0.4646 - val_loss: 1.2508 - val_accuracy: 0.4150\n",
      "Epoch 31/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.2241 - accuracy: 0.4639 - val_loss: 1.2520 - val_accuracy: 0.4265\n",
      "Epoch 32/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.2247 - accuracy: 0.4697 - val_loss: 1.2471 - val_accuracy: 0.4236\n",
      "Epoch 33/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.2220 - accuracy: 0.4639 - val_loss: 1.2419 - val_accuracy: 0.4323\n",
      "Epoch 34/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.2213 - accuracy: 0.4660 - val_loss: 1.2377 - val_accuracy: 0.4438\n",
      "Epoch 35/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.2227 - accuracy: 0.4747 - val_loss: 1.2469 - val_accuracy: 0.4265\n",
      "Epoch 36/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.2233 - accuracy: 0.4632 - val_loss: 1.2732 - val_accuracy: 0.3919\n",
      "Epoch 37/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.2209 - accuracy: 0.4711 - val_loss: 1.2430 - val_accuracy: 0.4236\n",
      "Epoch 38/1000\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2210 - accuracy: 0.4660 - val_loss: 1.2444 - val_accuracy: 0.4323\n",
      "Epoch 39/1000\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2196 - accuracy: 0.4653 - val_loss: 1.2412 - val_accuracy: 0.4352\n",
      "Epoch 40/1000\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2175 - accuracy: 0.4733 - val_loss: 1.2496 - val_accuracy: 0.4207\n",
      "Epoch 41/1000\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2191 - accuracy: 0.4697 - val_loss: 1.2286 - val_accuracy: 0.4697\n",
      "Epoch 42/1000\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2180 - accuracy: 0.4646 - val_loss: 1.2460 - val_accuracy: 0.4179\n",
      "Epoch 43/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.2166 - accuracy: 0.4711 - val_loss: 1.2450 - val_accuracy: 0.4323\n",
      "Epoch 44/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.2153 - accuracy: 0.4595 - val_loss: 1.2337 - val_accuracy: 0.4352\n",
      "Epoch 45/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.2150 - accuracy: 0.4697 - val_loss: 1.2349 - val_accuracy: 0.4409\n",
      "Epoch 46/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.2159 - accuracy: 0.4733 - val_loss: 1.2457 - val_accuracy: 0.4207\n",
      "Epoch 47/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.2145 - accuracy: 0.4632 - val_loss: 1.2565 - val_accuracy: 0.4063\n",
      "Epoch 48/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.2159 - accuracy: 0.4776 - val_loss: 1.2364 - val_accuracy: 0.4380\n",
      "Epoch 49/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.2132 - accuracy: 0.4704 - val_loss: 1.2372 - val_accuracy: 0.4380\n",
      "Epoch 50/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.2119 - accuracy: 0.4697 - val_loss: 1.2448 - val_accuracy: 0.4236\n",
      "Epoch 51/1000\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2131 - accuracy: 0.4653 - val_loss: 1.2459 - val_accuracy: 0.4207\n",
      "Epoch 52/1000\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2119 - accuracy: 0.4718 - val_loss: 1.2401 - val_accuracy: 0.4323\n",
      "Epoch 53/1000\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2121 - accuracy: 0.4725 - val_loss: 1.2411 - val_accuracy: 0.4294\n",
      "Epoch 54/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.2121 - accuracy: 0.4646 - val_loss: 1.2525 - val_accuracy: 0.4294\n",
      "Epoch 55/1000\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2119 - accuracy: 0.4653 - val_loss: 1.2538 - val_accuracy: 0.4121\n",
      "Epoch 56/1000\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2115 - accuracy: 0.4718 - val_loss: 1.2448 - val_accuracy: 0.4207\n",
      "Epoch 57/1000\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2100 - accuracy: 0.4675 - val_loss: 1.2367 - val_accuracy: 0.4352\n",
      "Epoch 58/1000\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2112 - accuracy: 0.4675 - val_loss: 1.2443 - val_accuracy: 0.4150\n",
      "Epoch 59/1000\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2078 - accuracy: 0.4660 - val_loss: 1.2437 - val_accuracy: 0.4236\n",
      "Epoch 60/1000\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2099 - accuracy: 0.4668 - val_loss: 1.2371 - val_accuracy: 0.4352\n",
      "Epoch 61/1000\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2104 - accuracy: 0.4725 - val_loss: 1.2524 - val_accuracy: 0.4150\n",
      "Epoch 62/1000\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1.2087 - accuracy: 0.4704 - val_loss: 1.2442 - val_accuracy: 0.4294\n",
      "Epoch 63/1000\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2100 - accuracy: 0.4740 - val_loss: 1.2408 - val_accuracy: 0.4323\n",
      "Epoch 64/1000\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2075 - accuracy: 0.4754 - val_loss: 1.2434 - val_accuracy: 0.4352\n",
      "Epoch 65/1000\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2067 - accuracy: 0.4754 - val_loss: 1.2324 - val_accuracy: 0.4294\n",
      "Epoch 66/1000\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2067 - accuracy: 0.4675 - val_loss: 1.2662 - val_accuracy: 0.4063\n",
      "Epoch 67/1000\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2083 - accuracy: 0.4697 - val_loss: 1.2522 - val_accuracy: 0.4179\n",
      "Epoch 68/1000\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2071 - accuracy: 0.4805 - val_loss: 1.2401 - val_accuracy: 0.4294\n",
      "Epoch 69/1000\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2048 - accuracy: 0.4747 - val_loss: 1.2378 - val_accuracy: 0.4236\n",
      "Epoch 70/1000\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2056 - accuracy: 0.4718 - val_loss: 1.2561 - val_accuracy: 0.4207\n",
      "Epoch 71/1000\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2081 - accuracy: 0.4711 - val_loss: 1.2421 - val_accuracy: 0.4265\n",
      "Epoch 72/1000\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2065 - accuracy: 0.4798 - val_loss: 1.2361 - val_accuracy: 0.4323\n",
      "Epoch 73/1000\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2048 - accuracy: 0.4653 - val_loss: 1.2559 - val_accuracy: 0.4150\n",
      "Epoch 74/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.2042 - accuracy: 0.4827 - val_loss: 1.2499 - val_accuracy: 0.4179\n",
      "Epoch 75/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.2037 - accuracy: 0.4733 - val_loss: 1.2339 - val_accuracy: 0.4265\n",
      "Epoch 76/1000\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2027 - accuracy: 0.4798 - val_loss: 1.2419 - val_accuracy: 0.4179\n",
      "Epoch 77/1000\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2049 - accuracy: 0.4733 - val_loss: 1.2389 - val_accuracy: 0.4207\n",
      "Epoch 78/1000\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2022 - accuracy: 0.4819 - val_loss: 1.2377 - val_accuracy: 0.4409\n",
      "Epoch 79/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.2045 - accuracy: 0.4747 - val_loss: 1.2421 - val_accuracy: 0.4352\n",
      "Epoch 80/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.2039 - accuracy: 0.4653 - val_loss: 1.2483 - val_accuracy: 0.4207\n",
      "Epoch 81/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.2041 - accuracy: 0.4805 - val_loss: 1.2462 - val_accuracy: 0.4179\n",
      "Epoch 82/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.2027 - accuracy: 0.4725 - val_loss: 1.2366 - val_accuracy: 0.4352\n",
      "Epoch 83/1000\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2010 - accuracy: 0.4769 - val_loss: 1.2325 - val_accuracy: 0.4409\n",
      "Epoch 84/1000\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2004 - accuracy: 0.4762 - val_loss: 1.2403 - val_accuracy: 0.4265\n",
      "Epoch 85/1000\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2019 - accuracy: 0.4697 - val_loss: 1.2372 - val_accuracy: 0.4323\n",
      "Epoch 86/1000\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2012 - accuracy: 0.4762 - val_loss: 1.2415 - val_accuracy: 0.4265\n",
      "Epoch 87/1000\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.1996 - accuracy: 0.4783 - val_loss: 1.2417 - val_accuracy: 0.4438\n",
      "Epoch 88/1000\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2001 - accuracy: 0.4834 - val_loss: 1.2369 - val_accuracy: 0.4409\n",
      "Epoch 89/1000\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1.1982 - accuracy: 0.4827 - val_loss: 1.2388 - val_accuracy: 0.4207\n",
      "Epoch 90/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1997 - accuracy: 0.4675 - val_loss: 1.2488 - val_accuracy: 0.4207\n",
      "Epoch 91/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1973 - accuracy: 0.4848 - val_loss: 1.2254 - val_accuracy: 0.4524\n",
      "Epoch 92/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1987 - accuracy: 0.4733 - val_loss: 1.2393 - val_accuracy: 0.4265\n",
      "Epoch 93/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1968 - accuracy: 0.4827 - val_loss: 1.2490 - val_accuracy: 0.4179\n",
      "Epoch 94/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1997 - accuracy: 0.4805 - val_loss: 1.2516 - val_accuracy: 0.4207\n",
      "Epoch 95/1000\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1.1967 - accuracy: 0.4834 - val_loss: 1.2391 - val_accuracy: 0.4409\n",
      "Epoch 96/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1960 - accuracy: 0.4805 - val_loss: 1.2460 - val_accuracy: 0.4265\n",
      "Epoch 97/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1969 - accuracy: 0.4805 - val_loss: 1.2545 - val_accuracy: 0.4236\n",
      "Epoch 98/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1940 - accuracy: 0.4848 - val_loss: 1.2415 - val_accuracy: 0.4179\n",
      "Epoch 99/1000\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1.1951 - accuracy: 0.4776 - val_loss: 1.2390 - val_accuracy: 0.4207\n",
      "Epoch 100/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1949 - accuracy: 0.4805 - val_loss: 1.2402 - val_accuracy: 0.4207\n",
      "Epoch 101/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1975 - accuracy: 0.4762 - val_loss: 1.2431 - val_accuracy: 0.4467\n",
      "Epoch 102/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1939 - accuracy: 0.4834 - val_loss: 1.2250 - val_accuracy: 0.4669\n",
      "Epoch 103/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1922 - accuracy: 0.4827 - val_loss: 1.2405 - val_accuracy: 0.4352\n",
      "Epoch 104/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1920 - accuracy: 0.4848 - val_loss: 1.2357 - val_accuracy: 0.4352\n",
      "Epoch 105/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1914 - accuracy: 0.4827 - val_loss: 1.2422 - val_accuracy: 0.4150\n",
      "Epoch 106/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1923 - accuracy: 0.4855 - val_loss: 1.2254 - val_accuracy: 0.4611\n",
      "Epoch 107/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1929 - accuracy: 0.4841 - val_loss: 1.2396 - val_accuracy: 0.4236\n",
      "Epoch 108/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1919 - accuracy: 0.4790 - val_loss: 1.2411 - val_accuracy: 0.4265\n",
      "Epoch 109/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1918 - accuracy: 0.4790 - val_loss: 1.2510 - val_accuracy: 0.4236\n",
      "Epoch 110/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1921 - accuracy: 0.4805 - val_loss: 1.2389 - val_accuracy: 0.4323\n",
      "Epoch 111/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1914 - accuracy: 0.4819 - val_loss: 1.2282 - val_accuracy: 0.4409\n",
      "Epoch 112/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1893 - accuracy: 0.4819 - val_loss: 1.2384 - val_accuracy: 0.4121\n",
      "Epoch 113/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1899 - accuracy: 0.4834 - val_loss: 1.2444 - val_accuracy: 0.4265\n",
      "Epoch 114/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1889 - accuracy: 0.4819 - val_loss: 1.2550 - val_accuracy: 0.4121\n",
      "Epoch 115/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1901 - accuracy: 0.4884 - val_loss: 1.2414 - val_accuracy: 0.4150\n",
      "Epoch 116/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1892 - accuracy: 0.4805 - val_loss: 1.2376 - val_accuracy: 0.4236\n",
      "Epoch 117/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1860 - accuracy: 0.4855 - val_loss: 1.2748 - val_accuracy: 0.4006\n",
      "Epoch 118/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1900 - accuracy: 0.4819 - val_loss: 1.2293 - val_accuracy: 0.4294\n",
      "Epoch 119/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1873 - accuracy: 0.4855 - val_loss: 1.2437 - val_accuracy: 0.4236\n",
      "Epoch 120/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1861 - accuracy: 0.4805 - val_loss: 1.2407 - val_accuracy: 0.4236\n",
      "Epoch 121/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1870 - accuracy: 0.4841 - val_loss: 1.2342 - val_accuracy: 0.4265\n",
      "Epoch 122/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1857 - accuracy: 0.4906 - val_loss: 1.2398 - val_accuracy: 0.4207\n",
      "Epoch 123/1000\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1.1846 - accuracy: 0.4884 - val_loss: 1.2346 - val_accuracy: 0.4438\n",
      "Epoch 124/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1893 - accuracy: 0.4877 - val_loss: 1.2387 - val_accuracy: 0.4294\n",
      "Epoch 125/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1842 - accuracy: 0.4855 - val_loss: 1.2289 - val_accuracy: 0.4438\n",
      "Epoch 126/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1838 - accuracy: 0.4834 - val_loss: 1.2547 - val_accuracy: 0.4121\n",
      "Epoch 127/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1827 - accuracy: 0.4798 - val_loss: 1.2455 - val_accuracy: 0.4236\n",
      "Epoch 128/1000\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1.1839 - accuracy: 0.4855 - val_loss: 1.2428 - val_accuracy: 0.4207\n",
      "Epoch 129/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1842 - accuracy: 0.4834 - val_loss: 1.2600 - val_accuracy: 0.4150\n",
      "Epoch 130/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1816 - accuracy: 0.4899 - val_loss: 1.2580 - val_accuracy: 0.4035\n",
      "Epoch 131/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1849 - accuracy: 0.4863 - val_loss: 1.2373 - val_accuracy: 0.4236\n",
      "Epoch 132/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1801 - accuracy: 0.4841 - val_loss: 1.2225 - val_accuracy: 0.4669\n",
      "Epoch 133/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1842 - accuracy: 0.4884 - val_loss: 1.2428 - val_accuracy: 0.4179\n",
      "Epoch 134/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1804 - accuracy: 0.4892 - val_loss: 1.2485 - val_accuracy: 0.3977\n",
      "Epoch 135/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1826 - accuracy: 0.4848 - val_loss: 1.2445 - val_accuracy: 0.4236\n",
      "Epoch 136/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1794 - accuracy: 0.4855 - val_loss: 1.2375 - val_accuracy: 0.4265\n",
      "Epoch 137/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1802 - accuracy: 0.4848 - val_loss: 1.2556 - val_accuracy: 0.4063\n",
      "Epoch 138/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1794 - accuracy: 0.4870 - val_loss: 1.2408 - val_accuracy: 0.4207\n",
      "Epoch 139/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1781 - accuracy: 0.4978 - val_loss: 1.2283 - val_accuracy: 0.4438\n",
      "Epoch 140/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1778 - accuracy: 0.4892 - val_loss: 1.2407 - val_accuracy: 0.4207\n",
      "Epoch 141/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1793 - accuracy: 0.4913 - val_loss: 1.2421 - val_accuracy: 0.4265\n",
      "Epoch 142/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1782 - accuracy: 0.4848 - val_loss: 1.2598 - val_accuracy: 0.4121\n",
      "Epoch 143/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1760 - accuracy: 0.4884 - val_loss: 1.2496 - val_accuracy: 0.4207\n",
      "Epoch 144/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1770 - accuracy: 0.4906 - val_loss: 1.2432 - val_accuracy: 0.4150\n",
      "Epoch 145/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1790 - accuracy: 0.4892 - val_loss: 1.2598 - val_accuracy: 0.4121\n",
      "Epoch 146/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1785 - accuracy: 0.4906 - val_loss: 1.2451 - val_accuracy: 0.4179\n",
      "Epoch 147/1000\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.1769 - accuracy: 0.4819 - val_loss: 1.2581 - val_accuracy: 0.4063\n",
      "Epoch 148/1000\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1.1748 - accuracy: 0.4964 - val_loss: 1.2247 - val_accuracy: 0.4524\n",
      "Epoch 149/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1760 - accuracy: 0.4913 - val_loss: 1.2555 - val_accuracy: 0.4236\n",
      "Epoch 150/1000\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1.1733 - accuracy: 0.4848 - val_loss: 1.2410 - val_accuracy: 0.4236\n",
      "Epoch 151/1000\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1.1724 - accuracy: 0.4949 - val_loss: 1.2519 - val_accuracy: 0.4236\n",
      "Epoch 152/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1742 - accuracy: 0.4921 - val_loss: 1.2540 - val_accuracy: 0.4150\n",
      "Epoch 153/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1726 - accuracy: 0.4899 - val_loss: 1.2392 - val_accuracy: 0.4294\n",
      "Epoch 154/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1726 - accuracy: 0.4949 - val_loss: 1.2499 - val_accuracy: 0.4035\n",
      "Epoch 155/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1706 - accuracy: 0.4913 - val_loss: 1.2702 - val_accuracy: 0.4006\n",
      "Epoch 156/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1780 - accuracy: 0.4906 - val_loss: 1.2624 - val_accuracy: 0.3977\n",
      "Epoch 157/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1710 - accuracy: 0.4913 - val_loss: 1.2502 - val_accuracy: 0.4035\n",
      "Epoch 158/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1707 - accuracy: 0.4913 - val_loss: 1.2489 - val_accuracy: 0.4179\n",
      "Epoch 159/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1696 - accuracy: 0.4899 - val_loss: 1.2547 - val_accuracy: 0.4063\n",
      "Epoch 160/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1710 - accuracy: 0.4971 - val_loss: 1.2464 - val_accuracy: 0.4150\n",
      "Epoch 161/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1679 - accuracy: 0.4957 - val_loss: 1.2585 - val_accuracy: 0.4179\n",
      "Epoch 162/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1671 - accuracy: 0.4928 - val_loss: 1.2665 - val_accuracy: 0.4092\n",
      "Epoch 163/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1672 - accuracy: 0.4978 - val_loss: 1.2499 - val_accuracy: 0.4063\n",
      "Epoch 164/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1679 - accuracy: 0.4986 - val_loss: 1.2662 - val_accuracy: 0.4121\n",
      "Epoch 165/1000\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1.1686 - accuracy: 0.4906 - val_loss: 1.2696 - val_accuracy: 0.4121\n",
      "Epoch 166/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1689 - accuracy: 0.4949 - val_loss: 1.2553 - val_accuracy: 0.4236\n",
      "Epoch 167/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1669 - accuracy: 0.4957 - val_loss: 1.2633 - val_accuracy: 0.4092\n",
      "Epoch 168/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1678 - accuracy: 0.4971 - val_loss: 1.2510 - val_accuracy: 0.4121\n",
      "Epoch 169/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1643 - accuracy: 0.4986 - val_loss: 1.2694 - val_accuracy: 0.4150\n",
      "Epoch 170/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1653 - accuracy: 0.4913 - val_loss: 1.2650 - val_accuracy: 0.4092\n",
      "Epoch 171/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1645 - accuracy: 0.5007 - val_loss: 1.2496 - val_accuracy: 0.4323\n",
      "Epoch 172/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1614 - accuracy: 0.5036 - val_loss: 1.2333 - val_accuracy: 0.4352\n",
      "Epoch 173/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1651 - accuracy: 0.4949 - val_loss: 1.2651 - val_accuracy: 0.4092\n",
      "Epoch 174/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1633 - accuracy: 0.5036 - val_loss: 1.2571 - val_accuracy: 0.4323\n",
      "Epoch 175/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1621 - accuracy: 0.4978 - val_loss: 1.2422 - val_accuracy: 0.4236\n",
      "Epoch 176/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1617 - accuracy: 0.4957 - val_loss: 1.2590 - val_accuracy: 0.3919\n",
      "Epoch 177/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1598 - accuracy: 0.4921 - val_loss: 1.2812 - val_accuracy: 0.3948\n",
      "Epoch 178/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1627 - accuracy: 0.5000 - val_loss: 1.2492 - val_accuracy: 0.4150\n",
      "Epoch 179/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1596 - accuracy: 0.4928 - val_loss: 1.2806 - val_accuracy: 0.4063\n",
      "Epoch 180/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1591 - accuracy: 0.4949 - val_loss: 1.2676 - val_accuracy: 0.4092\n",
      "Epoch 181/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1600 - accuracy: 0.4957 - val_loss: 1.2673 - val_accuracy: 0.4006\n",
      "Epoch 182/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1592 - accuracy: 0.4971 - val_loss: 1.2658 - val_accuracy: 0.3919\n",
      "Epoch 183/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1581 - accuracy: 0.5065 - val_loss: 1.2736 - val_accuracy: 0.4179\n",
      "Epoch 184/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1568 - accuracy: 0.4986 - val_loss: 1.2550 - val_accuracy: 0.4150\n",
      "Epoch 185/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1570 - accuracy: 0.4986 - val_loss: 1.2615 - val_accuracy: 0.4207\n",
      "Epoch 186/1000\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1.1557 - accuracy: 0.5058 - val_loss: 1.2607 - val_accuracy: 0.4063\n",
      "Epoch 187/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1567 - accuracy: 0.5043 - val_loss: 1.2515 - val_accuracy: 0.4207\n",
      "Epoch 188/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1566 - accuracy: 0.5007 - val_loss: 1.2674 - val_accuracy: 0.4092\n",
      "Epoch 189/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1548 - accuracy: 0.5022 - val_loss: 1.2824 - val_accuracy: 0.4035\n",
      "Epoch 190/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1548 - accuracy: 0.5108 - val_loss: 1.2699 - val_accuracy: 0.3977\n",
      "Epoch 191/1000\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1.1534 - accuracy: 0.5029 - val_loss: 1.2682 - val_accuracy: 0.4006\n",
      "Epoch 192/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1519 - accuracy: 0.5014 - val_loss: 1.2935 - val_accuracy: 0.3919\n",
      "Epoch 193/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1514 - accuracy: 0.5014 - val_loss: 1.2493 - val_accuracy: 0.4352\n",
      "Epoch 194/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1556 - accuracy: 0.5014 - val_loss: 1.2771 - val_accuracy: 0.4006\n",
      "Epoch 195/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1498 - accuracy: 0.5065 - val_loss: 1.2825 - val_accuracy: 0.4035\n",
      "Epoch 196/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1509 - accuracy: 0.4986 - val_loss: 1.2695 - val_accuracy: 0.3948\n",
      "Epoch 197/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1496 - accuracy: 0.5094 - val_loss: 1.2584 - val_accuracy: 0.4207\n",
      "Epoch 198/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1527 - accuracy: 0.5065 - val_loss: 1.2688 - val_accuracy: 0.4063\n",
      "Epoch 199/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1485 - accuracy: 0.5029 - val_loss: 1.2811 - val_accuracy: 0.3977\n",
      "Epoch 200/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1496 - accuracy: 0.5014 - val_loss: 1.2780 - val_accuracy: 0.4035\n",
      "Epoch 201/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1476 - accuracy: 0.5065 - val_loss: 1.2681 - val_accuracy: 0.4006\n",
      "Epoch 202/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1485 - accuracy: 0.5036 - val_loss: 1.2605 - val_accuracy: 0.4121\n",
      "Epoch 203/1000\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1.1470 - accuracy: 0.5029 - val_loss: 1.2899 - val_accuracy: 0.3919\n",
      "Epoch 204/1000\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1.1453 - accuracy: 0.5029 - val_loss: 1.2907 - val_accuracy: 0.3833\n",
      "Epoch 205/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1487 - accuracy: 0.5145 - val_loss: 1.2894 - val_accuracy: 0.3775\n",
      "Epoch 206/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1476 - accuracy: 0.5087 - val_loss: 1.2771 - val_accuracy: 0.3890\n",
      "Epoch 207/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1457 - accuracy: 0.5014 - val_loss: 1.2834 - val_accuracy: 0.3804\n",
      "Epoch 208/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1434 - accuracy: 0.5029 - val_loss: 1.2865 - val_accuracy: 0.3948\n",
      "Epoch 209/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1404 - accuracy: 0.5079 - val_loss: 1.2833 - val_accuracy: 0.3862\n",
      "Epoch 210/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1434 - accuracy: 0.5166 - val_loss: 1.2738 - val_accuracy: 0.4179\n",
      "Epoch 211/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1423 - accuracy: 0.5079 - val_loss: 1.2809 - val_accuracy: 0.3977\n",
      "Epoch 212/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1406 - accuracy: 0.5043 - val_loss: 1.2706 - val_accuracy: 0.3948\n",
      "Epoch 213/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1428 - accuracy: 0.5152 - val_loss: 1.2915 - val_accuracy: 0.4006\n",
      "Epoch 214/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1400 - accuracy: 0.5173 - val_loss: 1.2806 - val_accuracy: 0.3890\n",
      "Epoch 215/1000\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1.1387 - accuracy: 0.5029 - val_loss: 1.2732 - val_accuracy: 0.3977\n",
      "Epoch 216/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1386 - accuracy: 0.5094 - val_loss: 1.2779 - val_accuracy: 0.4006\n",
      "Epoch 217/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1373 - accuracy: 0.5181 - val_loss: 1.3098 - val_accuracy: 0.3804\n",
      "Epoch 218/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1369 - accuracy: 0.5152 - val_loss: 1.2862 - val_accuracy: 0.4006\n",
      "Epoch 219/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1377 - accuracy: 0.5058 - val_loss: 1.2796 - val_accuracy: 0.3948\n",
      "Epoch 220/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1356 - accuracy: 0.5137 - val_loss: 1.2896 - val_accuracy: 0.3746\n",
      "Epoch 221/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1360 - accuracy: 0.5036 - val_loss: 1.2943 - val_accuracy: 0.3775\n",
      "Epoch 222/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1340 - accuracy: 0.5101 - val_loss: 1.2806 - val_accuracy: 0.4006\n",
      "Epoch 223/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1378 - accuracy: 0.5101 - val_loss: 1.2858 - val_accuracy: 0.3890\n",
      "Epoch 224/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1313 - accuracy: 0.5123 - val_loss: 1.2868 - val_accuracy: 0.3775\n",
      "Epoch 225/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1338 - accuracy: 0.5101 - val_loss: 1.2891 - val_accuracy: 0.3718\n",
      "Epoch 226/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1329 - accuracy: 0.5065 - val_loss: 1.2903 - val_accuracy: 0.3862\n",
      "Epoch 227/1000\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1.1298 - accuracy: 0.5152 - val_loss: 1.2953 - val_accuracy: 0.3804\n",
      "Epoch 228/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1282 - accuracy: 0.5094 - val_loss: 1.3089 - val_accuracy: 0.3804\n",
      "Epoch 229/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1285 - accuracy: 0.5137 - val_loss: 1.2949 - val_accuracy: 0.3804\n",
      "Epoch 230/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1295 - accuracy: 0.5094 - val_loss: 1.2983 - val_accuracy: 0.3890\n",
      "Epoch 231/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1288 - accuracy: 0.5079 - val_loss: 1.2925 - val_accuracy: 0.3862\n",
      "Epoch 232/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1293 - accuracy: 0.5079 - val_loss: 1.3026 - val_accuracy: 0.3833\n",
      "Epoch 233/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1296 - accuracy: 0.5152 - val_loss: 1.3080 - val_accuracy: 0.3919\n",
      "Epoch 234/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1278 - accuracy: 0.5166 - val_loss: 1.3075 - val_accuracy: 0.3890\n",
      "Epoch 235/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1305 - accuracy: 0.5152 - val_loss: 1.2927 - val_accuracy: 0.3718\n",
      "Epoch 236/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1259 - accuracy: 0.5159 - val_loss: 1.3031 - val_accuracy: 0.3804\n",
      "Epoch 237/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1262 - accuracy: 0.5202 - val_loss: 1.3070 - val_accuracy: 0.3804\n",
      "Epoch 238/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1254 - accuracy: 0.5159 - val_loss: 1.3143 - val_accuracy: 0.3718\n",
      "Epoch 239/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1231 - accuracy: 0.5123 - val_loss: 1.3063 - val_accuracy: 0.3746\n",
      "Epoch 240/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1257 - accuracy: 0.5210 - val_loss: 1.3027 - val_accuracy: 0.3746\n",
      "Epoch 241/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1228 - accuracy: 0.5202 - val_loss: 1.3253 - val_accuracy: 0.3775\n",
      "Epoch 242/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1218 - accuracy: 0.5123 - val_loss: 1.2982 - val_accuracy: 0.3862\n",
      "Epoch 243/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1212 - accuracy: 0.5188 - val_loss: 1.3305 - val_accuracy: 0.3746\n",
      "Epoch 244/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1191 - accuracy: 0.5130 - val_loss: 1.2933 - val_accuracy: 0.3948\n",
      "Epoch 245/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1198 - accuracy: 0.5152 - val_loss: 1.3056 - val_accuracy: 0.3890\n",
      "Epoch 246/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1181 - accuracy: 0.5123 - val_loss: 1.2962 - val_accuracy: 0.3804\n",
      "Epoch 247/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1179 - accuracy: 0.5188 - val_loss: 1.3056 - val_accuracy: 0.3890\n",
      "Epoch 248/1000\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1.1182 - accuracy: 0.5238 - val_loss: 1.2938 - val_accuracy: 0.4035\n",
      "Epoch 249/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1191 - accuracy: 0.5137 - val_loss: 1.2931 - val_accuracy: 0.3977\n",
      "Epoch 250/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1192 - accuracy: 0.5181 - val_loss: 1.2976 - val_accuracy: 0.3919\n",
      "Epoch 251/1000\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1.1183 - accuracy: 0.5116 - val_loss: 1.2979 - val_accuracy: 0.3804\n",
      "Epoch 252/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1186 - accuracy: 0.5195 - val_loss: 1.3073 - val_accuracy: 0.3804\n",
      "Epoch 253/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1173 - accuracy: 0.5260 - val_loss: 1.3048 - val_accuracy: 0.3746\n",
      "Epoch 254/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1138 - accuracy: 0.5181 - val_loss: 1.2964 - val_accuracy: 0.3919\n",
      "Epoch 255/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1138 - accuracy: 0.5238 - val_loss: 1.3053 - val_accuracy: 0.3919\n",
      "Epoch 256/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1164 - accuracy: 0.5217 - val_loss: 1.3183 - val_accuracy: 0.3833\n",
      "Epoch 257/1000\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1.1142 - accuracy: 0.5275 - val_loss: 1.3188 - val_accuracy: 0.3890\n",
      "Epoch 258/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1123 - accuracy: 0.5303 - val_loss: 1.3000 - val_accuracy: 0.4092\n",
      "Epoch 259/1000\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1.1104 - accuracy: 0.5354 - val_loss: 1.3092 - val_accuracy: 0.3890\n",
      "Epoch 260/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1115 - accuracy: 0.5275 - val_loss: 1.3135 - val_accuracy: 0.3862\n",
      "Epoch 261/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1097 - accuracy: 0.5210 - val_loss: 1.3329 - val_accuracy: 0.3890\n",
      "Epoch 262/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1100 - accuracy: 0.5166 - val_loss: 1.3240 - val_accuracy: 0.3804\n",
      "Epoch 263/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1093 - accuracy: 0.5296 - val_loss: 1.3340 - val_accuracy: 0.3890\n",
      "Epoch 264/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1097 - accuracy: 0.5289 - val_loss: 1.3275 - val_accuracy: 0.3919\n",
      "Epoch 265/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1085 - accuracy: 0.5296 - val_loss: 1.2927 - val_accuracy: 0.4063\n",
      "Epoch 266/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1066 - accuracy: 0.5332 - val_loss: 1.3310 - val_accuracy: 0.3862\n",
      "Epoch 267/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1078 - accuracy: 0.5260 - val_loss: 1.3264 - val_accuracy: 0.3862\n",
      "Epoch 268/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1043 - accuracy: 0.5238 - val_loss: 1.3056 - val_accuracy: 0.3948\n",
      "Epoch 269/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1060 - accuracy: 0.5195 - val_loss: 1.3178 - val_accuracy: 0.3948\n",
      "Epoch 270/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1039 - accuracy: 0.5224 - val_loss: 1.3206 - val_accuracy: 0.3890\n",
      "Epoch 271/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1036 - accuracy: 0.5296 - val_loss: 1.3087 - val_accuracy: 0.3833\n",
      "Epoch 272/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1042 - accuracy: 0.5289 - val_loss: 1.3060 - val_accuracy: 0.3948\n",
      "Epoch 273/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1031 - accuracy: 0.5332 - val_loss: 1.3294 - val_accuracy: 0.3890\n",
      "Epoch 274/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1028 - accuracy: 0.5296 - val_loss: 1.3301 - val_accuracy: 0.3948\n",
      "Epoch 275/1000\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.1013 - accuracy: 0.5303 - val_loss: 1.3188 - val_accuracy: 0.3833\n",
      "Epoch 276/1000\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.0988 - accuracy: 0.5368 - val_loss: 1.3319 - val_accuracy: 0.3804\n",
      "Epoch 277/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1009 - accuracy: 0.5303 - val_loss: 1.3389 - val_accuracy: 0.3948\n",
      "Epoch 278/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.1000 - accuracy: 0.5318 - val_loss: 1.3295 - val_accuracy: 0.4006\n",
      "Epoch 279/1000\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1.1001 - accuracy: 0.5318 - val_loss: 1.3147 - val_accuracy: 0.3948\n",
      "Epoch 280/1000\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 1.1013 - accuracy: 0.5275 - val_loss: 1.3432 - val_accuracy: 0.3919\n",
      "Epoch 281/1000\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 1.0999 - accuracy: 0.5267 - val_loss: 1.3229 - val_accuracy: 0.3948\n",
      "Epoch 282/1000\n",
      "57/70 [=======================>......] - ETA: 0s - loss: 1.1049 - accuracy: 0.5456"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "\toptimizer='adam',\n",
    "\tloss='categorical_crossentropy',\n",
    "\tmetrics=['accuracy']\n",
    ")\n",
    "model.fit(\n",
    "\ttrain_X, train_y, \n",
    "\tvalidation_data=(val_X,val_y), \n",
    "\tepochs=1000, batch_size=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.25      0.32        20\n",
      "           1       0.40      0.38      0.39        77\n",
      "           2       0.47      0.61      0.53       181\n",
      "           3       0.37      0.40      0.38       108\n",
      "           4       0.00      0.00      0.00        47\n",
      "\n",
      "    accuracy                           0.43       433\n",
      "   macro avg       0.34      0.33      0.33       433\n",
      "weighted avg       0.38      0.43      0.40       433\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yfrom\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\yfrom\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\yfrom\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_X, batch_size=20)\n",
    "y_p= np.argmax(predictions, axis=1)\n",
    "y_t= np.argmax(test_y.to_numpy(), axis=1)\n",
    "print(classification_report(y_t, y_p))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
